# World State Autonomous Driving Lab  
（智能驾驶 · 世界状态驱动的深度学习实操代码骨架）

---

## 一、项目说明

本项目用于**教学、培训与技术验证（PoC）**，通过一个**最小但完整**的深度学习系统，演示智能驾驶中以下核心问题的工程化解决路径：

- 世界状态（World State）的构建方式  
- 世界状态的时序预测（World Model）  
- 世界状态在规划与控制中的使用方式  

项目目标不是复现工业级自动驾驶系统，而是帮助学员建立：

> **“如何用深度学习重新组织智能驾驶系统”的工程认知**

---

## 二、设计原则

- **统一对象**：所有模型围绕“世界状态（World State）”展开  
- **工程优先**：强调结构、接口与可扩展性  
- **实操可跑**：所有代码均可基于开源数据运行  
- **岗位可映射**：不同角色可从同一结构获得启发  

---

## 三、目录结构

world_state_autonomous_driving/  
├── README.md  
├── data/  
│   ├── nuscenes_sample/  
│   └── preprocess.py  
├── perception/  
│   ├── image_encoder.py  
│   ├── multi_view_fusion.py  
│   └── bev_projection.py  
├── multimodal/  
│   ├── vision_language.py  
│   └── text_instruction_encoder.py  
├── world_model/  
│   ├── state_encoder.py  
│   ├── dynamics_model.py  
│   └── rollout.py  
├── control/  
│   ├── policy_head.py  
│   └── planner.py  
├── engineering/  
│   ├── train_loop.py  
│   ├── inference_pipeline.py  
│   └── export_onnx.py  
└── notebooks/  
    ├── day1_world_state.ipynb  
    └── day2_project_mapping.ipynb  

---

## 四、模块说明

### 1. data/

**功能**
- 开源数据下载
- 数据裁剪、格式化与预处理

**推荐数据集**
- nuScenes（mini / sample）
- KITTI（演示用）

**教学重点**
- 数据本身不是目标  
- 数据服务于“世界状态”的构建  

---

### 2. perception/

**功能**
- 多视角感知 → 世界状态输入

**核心文件**
- image_encoder.py：CNN / ViT 视觉编码  
- multi_view_fusion.py：多视角特征融合  
- bev_projection.py：BEV / 3D 表示示意  

**教学重点**
- 感知输出不等于检测结果  
- 感知的目标是生成“可被后续模块消费的表示”  

---

### 3. multimodal/

**功能**
- 视觉与语言语义对齐  
- 为世界状态引入高层语义约束  

**核心文件**
- vision_language.py：CLIP 等 VLM 特征对齐  
- text_instruction_encoder.py：文本 / 指令编码  

**教学重点**
- VLM / VLA 不是替代感知  
- 语言是约束信号，而非控制信号  

---

### 4. world_model/

**功能**
- 世界状态的时序建模与预测  
- 构建“可学习的世界模型”  

**核心文件**
- state_encoder.py：世界状态表示 z_t  
- dynamics_model.py：z_t → z_{t+1}  
- rollout.py：世界状态推演  

**教学重点**
- 世界模型 ≈ 可学习的仿真器  
- 它是连接感知与控制的核心枢纽  

---

### 5. control/

**功能**
- 基于世界状态的决策与规划  

**核心文件**
- policy_head.py：状态 → 行为  
- planner.py：简单规划 / 策略示意  

**教学重点**
- 控制应消费“世界状态”  
- 而不是直接消费原始感知结果  

---

### 6. engineering/

**功能**
- 工程化训练、推理与部署示意  

**核心文件**
- train_loop.py：训练流程组织  
- inference_pipeline.py：推理结构示意  
- export_onnx.py：模型导出与部署接口  

**教学重点**
- 算法与工程结构解耦  
- 通用智能驾驶方案的可扩展性设计  

---

### 7. notebooks/

**功能**
- 教学与实验组织  

**内容说明**
- day1_world_state.ipynb  
  - 世界状态构建  
  - 世界模型基础  

- day2_project_mapping.ipynb  
  - 项目结构映射  
  - PoC 设计讨论  

---

## 五、培训使用建议

- **Day 1**
  - 跑通 perception + world_model  
  - 理解世界状态如何被“学出来”  

- **Day 2**
  - 扩展 multimodal + control + engineering  
  - 理解世界状态如何被“用起来”  

- **培训结束**
  - 结合企业在研项目，讨论最合适的 PoC 切入点  

---

## 六、使用边界说明（重要）

### 教学示意为主的模块
以下内容以结构理解与范式学习为主，不建议直接量产使用：

- BEV / 3D 投影示意  
- VLM / VLA 结构示例  
- 世界模型的简化实现  

---

### 可直接用于 PoC 的模块
以下内容可作为企业内部 PoC 的直接参考：

- 世界状态（World State）接口设计  
- 状态驱动的控制输入方式  
- 训练 / 推理 / 模型导出工程结构  

---

## 七、开源与合规说明

- 本项目全部基于可公开获取的开源数据与代码  
- 不包含任何商业闭源 SDK 或私有算法  
- 不依赖云端 API 或第三方在线服务  
- 可在企业内网环境中完整复现  

详细开源来源与许可说明，参见独立文档：  
开源数据与代码来源说明.md

---

## 八、总结

本代码骨架的价值不在于模型性能，而在于：

- 提供一套**统一的智能驾驶深度学习系统结构**  
- 帮助学员建立**可迁移、可扩展的工程认知**  
- 为企业在研项目提供清晰的 PoC 设计参考路径  

---

End of README
